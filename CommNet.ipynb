{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommNet:\n",
    "    \n",
    "    def __init__(self, sess, N, J, embedding_size = 128, lr = 1e-3, training_mode = 'supervised', alpha = 0.03):\n",
    "        \n",
    "        self.N = N\n",
    "        self.J = J\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.build_controler()\n",
    "        \n",
    "        self.training_mode = training_mode\n",
    "        \n",
    "        if training_mode == 'supervised':\n",
    "            self.build_supervised()\n",
    "            with tf.variable_scope('Supervised_optimizer'):\n",
    "                self.train_op = tf.train.AdamOptimizer(lr).minimize(self.supervised_loss)\n",
    "                \n",
    "        elif training_mode == 'reinforce':\n",
    "            self.alpha = 0.03\n",
    "            self.build_reinforce()\n",
    "            with tf.variable_scope('Reinforce_optimizer'):\n",
    "                self.train_op =  tf.train.RMSPropOptimizer(lr).minimize(self.reinforce_loss)\n",
    "            \n",
    "        else:\n",
    "            raise(ValueError(\"Unknown training mode: %s\" % training_mode))\n",
    "        \n",
    "        print(\"All variables\")\n",
    "        for var in tf.global_variables():\n",
    "            print(var)\n",
    "            \n",
    "        \n",
    "        self.sess = sess\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def encode(self, inputs):\n",
    "        \n",
    "        with tf.variable_scope('Encoder'):\n",
    "        \n",
    "            self.identity_embeddings = tf.get_variable(\"identity_embeddings\",\n",
    "                                             [self.N, self.embedding_size])\n",
    "            \n",
    "            self.embedded_identities = tf.nn.embedding_lookup(self.identity_embeddings, inputs)\n",
    "        \n",
    "            \n",
    "        return tf.unstack(self.embedded_identities, axis = 1)\n",
    "    \n",
    "    def build_f(self, name, h, c, h0 = None):\n",
    "        \n",
    "        with tf.variable_scope(name, reuse = tf.AUTO_REUSE):\n",
    "            \n",
    "            if h0 is not None:\n",
    "            \n",
    "                b1 = tf.get_variable('b1', shape = (1, self.embedding_size))\n",
    "                W1 = tf.get_variable('W1', shape = (3 * self.embedding_size,\n",
    "                                                  self.embedding_size))\n",
    "                \n",
    "                W2 = tf.get_variable('W2', shape = (self.embedding_size,\n",
    "                                                  self.embedding_size))\n",
    "                \n",
    "                concat = tf.concat([h, c, h0], axis = 1)\n",
    "            \n",
    "            else:\n",
    "                b1 = tf.get_variable('b1', shape = (1, self.embedding_size))\n",
    "                \n",
    "                W1 = tf.get_variable('W1', shape = (self.embedding_size,\n",
    "                                                  self.embedding_size))\n",
    "                \n",
    "                W2 = tf.get_variable('W2', shape = (self.embedding_size,\n",
    "                                                  self.embedding_size))\n",
    "                \n",
    "                concat = h\n",
    "            \n",
    "            b2 = tf.get_variable('b2', shape = (1, self.embedding_size))\n",
    "            \n",
    "            dense1 =tf.nn.relu(tf.einsum(\"ij,jk->ik\", concat, W1) + b1)\n",
    "            dense2 = tf.nn.relu(tf.einsum(\"ij,jk->ik\", dense1, W2) + b2)\n",
    "            \n",
    "            return dense2\n",
    "        \n",
    "    def decode(self, h):\n",
    "        \n",
    "        with tf.variable_scope('Decoder', reuse = tf.AUTO_REUSE):\n",
    "            \n",
    "            W = tf.get_variable('W', shape = (self.embedding_size,\n",
    "                                                  self.J))\n",
    "            \n",
    "            b = tf.get_variable('b', shape = (1, self.J))\n",
    "            \n",
    "            policy_logit = tf.einsum(\"ij,jk->ik\", h, W) + b\n",
    "        \n",
    "            return policy_logit\n",
    "    \n",
    "    \n",
    "    def communicate(self, h_seq):\n",
    "        \n",
    "        return tf.add_n(h_seq) / (self.J - 1)\n",
    "    \n",
    "    def sample_actions(self, log_proba):\n",
    "        \n",
    "        action = tf.multinomial(log_proba, num_samples = 1)\n",
    "        \n",
    "        return action\n",
    "    \n",
    "        \n",
    "    def build_controler(self):\n",
    "        \n",
    "        self.inputs = tf.placeholder(tf.int32, shape = (None, self.J))\n",
    "        \n",
    "        h0_seq = self.encode(self.inputs)\n",
    "        \n",
    "        h1_seq = [self.build_f(\"Comm_step_1\", h0_seq[j], None, None) for j in range(self.J)]\n",
    "        c1_seq = [self.communicate([h1_seq[j] for j in range(self.J) if j != i]) for i in range(self.J)]\n",
    "        \n",
    "        self.h2_seq = [self.build_f(\"Comm_step_2\", h1_seq[j], c1_seq[j], h0_seq[j]) for j in range(self.J)]\n",
    "        \n",
    "        self.layers = {'h0_seq': h0_seq, 'h1_seq': h1_seq, 'c1_seq':c1_seq, 'h2_seq': self.h2_seq}\n",
    "        \n",
    "        \n",
    "        self.policy_logit_seq = [self.decode(h2) for h2 in self.h2_seq]\n",
    "        \n",
    "        self.log_proba_seq = [tf.nn.log_softmax(policy_logit, axis = 1) for policy_logit in self.policy_logit_seq]\n",
    "        \n",
    "        self.action_seq = [self.sample_actions(log_proba) for log_proba in self.log_proba_seq]\n",
    "        \n",
    "        self.one_hot_action_seq = [tf.one_hot(action, depth = self.J) for action in self.action_seq]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def build_supervised(self):\n",
    "        \n",
    "        assert self.training_mode == 'supervised', 'Wrong training mode'\n",
    "        \n",
    "        self.targets = tf.placeholder(tf.int32, shape = (None, self.J))\n",
    "        unstacked_targets = tf.unstack(self.targets, axis = 1)\n",
    "        \n",
    "        supervised_loss_seq = [tf.nn.sparse_softmax_cross_entropy_with_logits(labels=unstacked_targets[j],\n",
    "                                                                                   logits=self.policy_logit_seq[j])\n",
    "                                    for j in range(self.J)]\n",
    "        \n",
    "        self.supervised_loss = tf.reduce_mean(supervised_loss_seq)\n",
    "        \n",
    "        \n",
    "    def supervised_train(self, X, y, val_X, val_y, env, batch_size = 32, epochs = 1):\n",
    "        \n",
    "        assert self.training_mode == 'supervised', 'Wrong training mode'\n",
    "        \n",
    "        n = X.shape[0]\n",
    "        \n",
    "        val_n = val_X.shape[0]\n",
    "        \n",
    "        data_inds = np.array(range(n))\n",
    "        for ep in range(1, epochs + 1):\n",
    "            np.random.shuffle(data_inds)\n",
    "            supervised_loss_sum = 0\n",
    "            reward_sum = 0\n",
    "            for i in tqdm_notebook(range(0, n, batch_size), \"Epoch: %d\" % ep):\n",
    "                inds_batch = data_inds[i:i+batch_size]\n",
    "                X_batch = X[inds_batch]\n",
    "                y_batch = y[inds_batch]\n",
    "                _, supervised_loss, one_hot_action_seq = sess.run([self.train_op, self.supervised_loss, self.one_hot_action_seq], feed_dict={self.inputs: X_batch, self.targets: y_batch})\n",
    "                supervised_loss_sum += supervised_loss * batch_size\n",
    "                reward_sum += env.get_reward(one_hot_action_seq)\n",
    "            \n",
    "            print(\"loss = %f\" % (supervised_loss_sum / n))\n",
    "            print(\"reward = %f\" % (reward_sum / n))\n",
    "            print()\n",
    "            \n",
    "            val_supervised_loss, val_one_hot_action_seq = sess.run([self.supervised_loss, self.one_hot_action_seq], feed_dict={self.inputs: val_X, self.targets: val_y})\n",
    "            print('val loss = %f' % (val_supervised_loss))\n",
    "            print('val reward = %f' % (env.get_reward(val_one_hot_action_seq) / val_n))\n",
    "            \n",
    "    def build_baseline(self, h):\n",
    "        \n",
    "        assert self.training_mode == 'reinforce', 'Wrong training mode'\n",
    "        \n",
    "        with tf.variable_scope('Baseline', reuse = tf.AUTO_REUSE):\n",
    "            \n",
    "            W = tf.get_variable('W', shape = (self.embedding_size,\n",
    "                                                  1))\n",
    "            \n",
    "            b = tf.get_variable('b', shape = (1,))\n",
    "            \n",
    "            \n",
    "            baseline = tf.einsum(\"ij,jk->ik\", h, W) + b\n",
    "            \n",
    "            return baseline\n",
    "            \n",
    "\n",
    "    def build_reinforce(self):\n",
    "        \n",
    "        assert self.training_mode == 'reinforce', 'Wrong training mode'\n",
    "        \n",
    "        self.indices = tf.placeholder(tf.int32, shape = (None, 2))\n",
    "        \n",
    "        self.shape = tf.placeholder(tf.int32, shape =(2,))\n",
    "        \n",
    "        self.baselines = tf.concat([self.build_baseline(h2) for h2 in self.h2_seq], axis = 1)\n",
    "        scattered_baselines = tf.scatter_nd(self.indices, tf.reshape(self.baselines, [-1]), shape = self.shape)\n",
    "                    \n",
    "        self.repeated_reward_values = tf.placeholder(tf.float32, shape = (None,))\n",
    "        scattered_reward_values = tf.scatter_nd(self.indices, self.repeated_reward_values, shape = self.shape)\n",
    "        scattered_reward_values_cumsum = tf.cumsum(scattered_reward_values, axis = 0, reverse = True)\n",
    "        \n",
    "        self.baseline_values =  tf.placeholder(tf.float32, shape = (None, self.J))\n",
    "        scattered_baseline_values = tf.scatter_nd(self.indices, tf.reshape(self.baseline_values, [-1]), shape = self.shape)\n",
    "        \n",
    "        \n",
    "        self.action_taken = tf.placeholder(tf.int32, shape = (None, self.J))\n",
    "        unstacked_action_taken = tf.unstack(self.action_taken, axis = 1)\n",
    "        \n",
    "        self.neg_log_p = tf.transpose(tf.concat([[tf.nn.sparse_softmax_cross_entropy_with_logits(labels=unstacked_action_taken[j],\n",
    "                                                    logits=self.policy_logit_seq[j])] for j in range(self.J)], axis = 0))\n",
    "        \n",
    "        print(self.neg_log_p)\n",
    "        \n",
    "        scattered_neg_log_p = tf.scatter_nd(self.indices, tf.reshape(self.neg_log_p, [-1]), shape = self.shape)\n",
    "        \n",
    "        #surrogate loss (- dtheta)\n",
    "        self.reinforce_loss = tf.reduce_sum(tf.multiply(scattered_neg_log_p, scattered_reward_values_cumsum - scattered_baseline_values))\n",
    "        self.reinforce_loss += self.alpha * tf.reduce_sum(tf.square(scattered_reward_values_cumsum - scattered_baselines))\n",
    "        \n",
    "        \n",
    "    def take_action(self, state):\n",
    "        \n",
    "        assert self.training_mode == 'reinforce', 'Wrong training mode'\n",
    "        \n",
    "        action_seq, baselines= self.sess.run([self.action_seq, self.baselines], {self.inputs: [state]})\n",
    "        \n",
    "        return [a[0,0] for a in action_seq], baselines\n",
    "    \n",
    "    def reinforce_train(self, env, n_episodes, T):\n",
    "        \n",
    "        assert self.training_mode == 'reinforce', 'Wrong training mode'\n",
    "        \n",
    "        \n",
    "        history = {'reward' : [],  'loss': []}    \n",
    "        \n",
    "        for _ in tqdm_notebook(range(n_episodes), \"REINFORCE\"):\n",
    "            \n",
    "            \n",
    "            state_seq, action_seq, reward_seq, baseline_seq = policy_rollout(T, env, self)\n",
    "            episode_len = reward_seq.shape[0]\n",
    "            \n",
    "            history['reward'].append(np.mean(reward_seq))\n",
    "            \n",
    "            repeated_t = np.repeat(np.arange(episode_len), self.J)\n",
    "            \n",
    "            indices = np.vstack([repeated_t, state_seq.ravel()]) .T\n",
    "                \n",
    "            feed_dict = {}\n",
    "            feed_dict[self.inputs] = state_seq\n",
    "            feed_dict[self.indices] = indices\n",
    "            feed_dict[self.shape] = [episode_len, self.N]\n",
    "            feed_dict[self.repeated_reward_values] = np.repeat(reward_seq, self.J)\n",
    "            feed_dict[self.baseline_values] = baseline_seq\n",
    "            feed_dict[self.action_taken] = action_seq\n",
    "            \n",
    "            _, loss = self.sess.run([self.train_op, self.reinforce_loss], feed_dict = feed_dict)\n",
    "            \n",
    "            history['loss'].append(loss)\n",
    "            \n",
    "            \n",
    "        return history\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeverEnv:\n",
    "    \n",
    "    def __init__(self, N, J):\n",
    "        \n",
    "        self.J = J\n",
    "        self.N = N\n",
    "        \n",
    "    def reset(self):\n",
    "        \n",
    "        state = np.random.choice(self.N, size = self.J, replace = False)\n",
    "        \n",
    "        terminal_state = False\n",
    "        \n",
    "        return state, terminal_state\n",
    "    \n",
    "    def get_reward(self, one_hot_action_seq):        \n",
    "        \n",
    "        reward = np.sum(np.sum(one_hot_action_seq, axis = 0) > 0) /self.J\n",
    "        \n",
    "        return reward\n",
    "        \n",
    "    def step(self, state, action):\n",
    "        \n",
    "        next_state = np.random.choice(self.N, size = self.J, replace = False)\n",
    "        \n",
    "        one_hot_action_seq = np.zeros((self.J, self.J))\n",
    "        one_hot_action_seq[range(self.J), action] = 1\n",
    "        reward = self.get_reward(one_hot_action_seq)\n",
    "        \n",
    "        terminal_state = False\n",
    "        \n",
    "        return next_state, reward, terminal_state\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation for supervised learning\n",
    "def generate_data(n, N, J):\n",
    "    \n",
    "    X = np.empty((n, J), dtype = int)\n",
    "    y= np.empty((n,J), dtype = int)\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        X[i] = np.random.choice(N, size = J, replace = False)\n",
    "        sorted_args = np.argsort(X[i])\n",
    "        y[i] = np.argsort(sorted_args)\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# episode generation for reinforcement learning\n",
    "def policy_rollout(T, env, agent):\n",
    "    \n",
    "    state_seq = []\n",
    "    action_seq = []\n",
    "    reward_seq = []\n",
    "    baseline_seq = []\n",
    "    \n",
    "    \n",
    "    state, terminal_state = env.reset()\n",
    "    \n",
    "    t = 0\n",
    "    \n",
    "    while not terminal_state and t < T:\n",
    "        t +=1\n",
    "        \n",
    "        state_seq.append(state)\n",
    "        action, baseline = agent.take_action(state)\n",
    "        \n",
    "        state, reward, terminal_state = env.step(state, action)\n",
    "        \n",
    "        \n",
    "        action_seq.append(action)\n",
    "        reward_seq.append(reward)\n",
    "        baseline_seq.append(baseline)\n",
    "        \n",
    "    return np.array(state_seq), np.array(action_seq), np.array(reward_seq), np.squeeze(np.array(baseline_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "J = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size * 1000\n",
    "X, y = generate_data(n, N, J)\n",
    "val_X, val_y = generate_data(500, N, J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"transpose:0\", shape=(?, 5), dtype=float32)\n",
      "All variables\n",
      "<tf.Variable 'Encoder/identity_embeddings:0' shape=(500, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Comm_step_1/b1:0' shape=(1, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Comm_step_1/W1:0' shape=(128, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Comm_step_1/W2:0' shape=(128, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Comm_step_1/b2:0' shape=(1, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Comm_step_2/b1:0' shape=(1, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Comm_step_2/W1:0' shape=(384, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Comm_step_2/W2:0' shape=(128, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Comm_step_2/b2:0' shape=(1, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Decoder/W:0' shape=(128, 5) dtype=float32_ref>\n",
      "<tf.Variable 'Decoder/b:0' shape=(1, 5) dtype=float32_ref>\n",
      "<tf.Variable 'Baseline/W:0' shape=(128, 1) dtype=float32_ref>\n",
      "<tf.Variable 'Baseline/b:0' shape=(1,) dtype=float32_ref>\n",
      "<tf.Variable 'Reinforce_optimizer/Encoder/identity_embeddings/RMSProp:0' shape=(500, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Reinforce_optimizer/Encoder/identity_embeddings/RMSProp_1:0' shape=(500, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Reinforce_optimizer/Comm_step_1/b1/RMSProp:0' shape=(1, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Reinforce_optimizer/Comm_step_1/b1/RMSProp_1:0' shape=(1, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Reinforce_optimizer/Comm_step_1/W1/RMSProp:0' shape=(128, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Reinforce_optimizer/Comm_step_1/W1/RMSProp_1:0' shape=(128, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Reinforce_optimizer/Comm_step_1/W2/RMSProp:0' shape=(128, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Reinforce_optimizer/Comm_step_1/W2/RMSProp_1:0' shape=(128, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Reinforce_optimizer/Comm_step_1/b2/RMSProp:0' shape=(1, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Reinforce_optimizer/Comm_step_1/b2/RMSProp_1:0' shape=(1, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Reinforce_optimizer/Comm_step_2/b1/RMSProp:0' shape=(1, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Reinforce_optimizer/Comm_step_2/b1/RMSProp_1:0' shape=(1, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Reinforce_optimizer/Comm_step_2/W1/RMSProp:0' shape=(384, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Reinforce_optimizer/Comm_step_2/W1/RMSProp_1:0' shape=(384, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Reinforce_optimizer/Comm_step_2/W2/RMSProp:0' shape=(128, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Reinforce_optimizer/Comm_step_2/W2/RMSProp_1:0' shape=(128, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Reinforce_optimizer/Comm_step_2/b2/RMSProp:0' shape=(1, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Reinforce_optimizer/Comm_step_2/b2/RMSProp_1:0' shape=(1, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Reinforce_optimizer/Decoder/W/RMSProp:0' shape=(128, 5) dtype=float32_ref>\n",
      "<tf.Variable 'Reinforce_optimizer/Decoder/W/RMSProp_1:0' shape=(128, 5) dtype=float32_ref>\n",
      "<tf.Variable 'Reinforce_optimizer/Decoder/b/RMSProp:0' shape=(1, 5) dtype=float32_ref>\n",
      "<tf.Variable 'Reinforce_optimizer/Decoder/b/RMSProp_1:0' shape=(1, 5) dtype=float32_ref>\n",
      "<tf.Variable 'Reinforce_optimizer/Baseline/W/RMSProp:0' shape=(128, 1) dtype=float32_ref>\n",
      "<tf.Variable 'Reinforce_optimizer/Baseline/W/RMSProp_1:0' shape=(128, 1) dtype=float32_ref>\n",
      "<tf.Variable 'Reinforce_optimizer/Baseline/b/RMSProp:0' shape=(1,) dtype=float32_ref>\n",
      "<tf.Variable 'Reinforce_optimizer/Baseline/b/RMSProp_1:0' shape=(1,) dtype=float32_ref>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccbe4ff88add4512b047791de7386eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='REINFORCE', style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    commNet = CommNet(sess, N, J, lr = 1e-3, embedding_size= 128, training_mode = 'reinforce')\n",
    "    env = LeverEnv(N, J)\n",
    "    \n",
    "    #commNet.supervised_train(X, y, val_X, val_y, env, batch_size = batch_size, epochs = 1)\n",
    "    #rv = sess.run([commNet.embedded_identities, commNet.identity_embeddings, commNet.layers], feed_dict = {commNet.inputs: val_X[0:2], commNet.targets: val_y[0:2]})\n",
    "    \n",
    "    history = commNet.reinforce_train(env, n_episodes = 100, T =64)\n",
    "    #state_seq, action_seq, reward_seq, proba_seq = policy_rollout(T = 32, env = env, agent = commNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x214867b77b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x214868bebe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x214864524e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "W = 30\n",
    "plt.plot(np.convolve(history['reward'], np.ones(W), mode= 'valid')/W)\n",
    "plt.show()\n",
    "plt.plot(history['reward'], '*')\n",
    "plt.show()\n",
    "plt.plot(history['loss'], '*')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.22577909 0.26917762 0.21279874 0.16583364 0.12641096]\n",
      "[0.22016849 0.22563423 0.22212386 0.19095235 0.14112104]\n",
      "[0.21960501 0.23955436 0.22702406 0.1854479  0.12836868]\n",
      "[0.23304532 0.20993459 0.22559714 0.1791272  0.15229584]\n",
      "[0.20872119 0.25417063 0.2264204  0.18819685 0.12249094]\n",
      "\n",
      "[0.21246645 0.20228745 0.23133822 0.20866685 0.145241  ]\n",
      "[0.22078106 0.24104035 0.21198149 0.18721826 0.13897899]\n",
      "[0.22285442 0.24080707 0.21916117 0.18383345 0.13334392]\n",
      "[0.21217397 0.23280925 0.22768702 0.18952763 0.13780206]\n",
      "[0.19502863 0.266822   0.22554079 0.19426489 0.11834362]\n",
      "\n",
      "[0.21161614 0.22226155 0.22272208 0.20031306 0.14308715]\n",
      "[0.21610449 0.21933357 0.22805688 0.19413775 0.14236726]\n",
      "[0.21205838 0.24951085 0.22500771 0.18818292 0.12524009]\n",
      "[0.21903999 0.209828   0.22463156 0.1948897  0.15161072]\n",
      "[0.23773776 0.18132898 0.2302288  0.18018381 0.1705207 ]\n",
      "\n",
      "[0.22067125 0.21549195 0.22589959 0.18399791 0.15393928]\n",
      "[0.21357127 0.24210793 0.22301947 0.1944984  0.12680286]\n",
      "[0.19097054 0.26365468 0.22255631 0.20049433 0.12232405]\n",
      "[0.20663887 0.21646273 0.22846274 0.19785467 0.15058103]\n",
      "[0.22137447 0.24524052 0.22064109 0.18040796 0.13233596]\n",
      "\n",
      "[0.21273632 0.27325147 0.21687391 0.18208349 0.11505479]\n",
      "[0.21884504 0.17979847 0.22955675 0.19940954 0.17239021]\n",
      "[0.21262266 0.23367149 0.22358938 0.19422908 0.13588746]\n",
      "[0.20483091 0.24535905 0.22289643 0.20298672 0.12392694]\n",
      "[0.2084316  0.22355096 0.22518164 0.20294471 0.13989106]\n",
      "\n",
      "[0.21515833 0.25627574 0.21566689 0.1896695  0.12322953]\n",
      "[0.22201861 0.23017275 0.21299037 0.1924831  0.14233515]\n",
      "[0.22445299 0.21772277 0.22435541 0.18528838 0.14818045]\n",
      "[0.22104214 0.23070513 0.21883635 0.19339964 0.13601676]\n",
      "[0.19676661 0.2526027  0.21903415 0.20721771 0.12437885]\n",
      "\n",
      "[0.20228599 0.24850874 0.23029636 0.19560495 0.123304  ]\n",
      "[0.2182514  0.22181627 0.21483353 0.19872467 0.1463741 ]\n",
      "[0.19929163 0.2923511  0.22015017 0.1808424  0.10736468]\n",
      "[0.21556234 0.19653839 0.22875148 0.20302154 0.15612626]\n",
      "[0.22088917 0.25919026 0.22333202 0.17557827 0.1210103 ]\n",
      "\n",
      "[0.22587304 0.23412181 0.22014292 0.18033369 0.13952859]\n",
      "[0.19374302 0.28093624 0.21820995 0.18939918 0.11771164]\n",
      "[0.23887664 0.20537795 0.22238486 0.17275184 0.1606087 ]\n",
      "[0.21140741 0.27057752 0.21198142 0.18626213 0.1197715 ]\n",
      "[0.22044031 0.22303139 0.22745937 0.19004355 0.13902539]\n",
      "\n",
      "[0.22322835 0.23330982 0.21863092 0.18879935 0.13603158]\n",
      "[0.20441993 0.24153438 0.22034948 0.20022811 0.13346808]\n",
      "[0.22479907 0.17664994 0.22958146 0.20128347 0.16768607]\n",
      "[0.20314576 0.26889065 0.22400092 0.182432   0.1215307 ]\n",
      "[0.22264437 0.20883307 0.22704281 0.18591653 0.15556322]\n",
      "\n",
      "[0.199008   0.26639315 0.21015826 0.20305236 0.12138826]\n",
      "[0.21561523 0.19152333 0.22673585 0.21264035 0.15348524]\n",
      "[0.2170282  0.28845745 0.21211468 0.16680405 0.11559568]\n",
      "[0.22135438 0.22084105 0.22300418 0.19301279 0.14178762]\n",
      "[0.22422238 0.2211677  0.22981626 0.18066835 0.14412531]\n",
      "\n",
      "[0.22514324 0.22562744 0.22113031 0.18151888 0.14658013]\n",
      "[0.20431758 0.26378307 0.2174363  0.19740634 0.1170566 ]\n",
      "[0.2368012  0.2082748  0.22363496 0.17244639 0.15884258]\n",
      "[0.21100225 0.24214143 0.21812712 0.19854775 0.13018143]\n",
      "[0.21134908 0.22557086 0.22715852 0.20109454 0.13482702]\n",
      "\n",
      "[0.22626516 0.18566026 0.22471897 0.18969189 0.1736637 ]\n",
      "[0.20991464 0.25449887 0.2258145  0.18517894 0.12459311]\n",
      "[0.22069362 0.24726129 0.22686833 0.1762484  0.12892841]\n",
      "[0.20973772 0.26549277 0.22524078 0.18327665 0.116252  ]\n",
      "[0.2118957  0.2509564  0.2239978  0.18862678 0.12452329]\n",
      "\n",
      "[0.2101295  0.25218526 0.22439171 0.18651812 0.12677541]\n",
      "[0.21472137 0.24148871 0.21937814 0.19266425 0.13174753]\n",
      "[0.23081045 0.23686497 0.21910216 0.17353235 0.13969003]\n",
      "[0.21773103 0.23980184 0.21924724 0.18883158 0.13438825]\n",
      "[0.21487397 0.22111182 0.23117046 0.1932943  0.1395495 ]\n",
      "\n",
      "[0.20635821 0.26365712 0.22638686 0.18581165 0.11778607]\n",
      "[0.21954602 0.20566517 0.22864355 0.20035584 0.14578947]\n",
      "[0.21879186 0.20527467 0.22829539 0.19490157 0.15273647]\n",
      "[0.21706122 0.23320886 0.22581665 0.18702163 0.1368916 ]\n",
      "[0.21573366 0.244135   0.22181426 0.18929574 0.12902136]\n",
      "\n",
      "[0.2261781  0.22176473 0.2223674  0.18294217 0.14674762]\n",
      "[0.2324129  0.2323909  0.2259613  0.16622347 0.14301144]\n",
      "[0.223666   0.22869422 0.21664909 0.18957786 0.14141288]\n",
      "[0.21635199 0.26867145 0.21707292 0.1781983  0.11970543]\n",
      "[0.21058594 0.26792142 0.21386865 0.18625474 0.12136929]\n",
      "\n",
      "[0.21900554 0.27957806 0.21360026 0.16925924 0.11855692]\n",
      "[0.21758318 0.22675206 0.22479232 0.19522502 0.13564745]\n",
      "[0.21561496 0.2226774  0.22310126 0.19989221 0.13871422]\n",
      "[0.22004586 0.22492802 0.22480641 0.18849096 0.14172868]\n",
      "[0.21800584 0.23378427 0.22219999 0.19081149 0.13519843]\n",
      "\n",
      "[0.22582246 0.21584377 0.2234601  0.18971166 0.145162  ]\n",
      "[0.21070836 0.21008064 0.23430248 0.20078133 0.14412715]\n",
      "[0.2212988  0.23203872 0.21632804 0.1932803  0.13705416]\n",
      "[0.21538837 0.2058449  0.21889244 0.21310675 0.1467675 ]\n",
      "[0.20461465 0.22141637 0.22226937 0.21192102 0.13977863]\n",
      "\n",
      "[0.23294911 0.20212069 0.22606169 0.18193467 0.15693387]\n",
      "[0.21150687 0.26200047 0.22102927 0.18700728 0.11845612]\n",
      "[0.21629757 0.24012014 0.23111641 0.17988157 0.13258427]\n",
      "[0.22124466 0.18187322 0.22651902 0.2029261  0.16743705]\n",
      "[0.20685111 0.237456   0.23659691 0.18889701 0.13019904]\n",
      "\n",
      "[0.20221321 0.27126384 0.21056388 0.19744538 0.11851368]\n",
      "[0.22074497 0.20906119 0.22518636 0.19735646 0.14765099]\n",
      "[0.21683772 0.24824983 0.22343048 0.18463497 0.12684692]\n",
      "[0.2153699  0.26178768 0.21690504 0.19567622 0.11026114]\n",
      "[0.21339647 0.2535094  0.22497979 0.18731694 0.12079737]\n",
      "\n",
      "[0.20888518 0.23938785 0.22481892 0.18889792 0.13801011]\n",
      "[0.21084663 0.2434294  0.21788357 0.19527963 0.1325607 ]\n",
      "[0.19798142 0.22632645 0.21650863 0.22195162 0.13723189]\n",
      "[0.21389768 0.22195657 0.22570361 0.19780852 0.1406336 ]\n",
      "[0.21610823 0.26128328 0.21765661 0.18000183 0.12495017]\n",
      "\n",
      "[0.21751736 0.22671232 0.22815238 0.18517886 0.14243908]\n",
      "[0.21485777 0.24024451 0.21763209 0.19247828 0.13478729]\n",
      "[0.21562827 0.18049154 0.22547483 0.21447591 0.16392948]\n",
      "[0.22050123 0.21901473 0.22775455 0.19005749 0.14267196]\n",
      "[0.21664326 0.22791618 0.22642538 0.19405943 0.13495572]\n",
      "\n",
      "[0.21997586 0.23556451 0.22273001 0.18846911 0.13326049]\n",
      "[0.22857894 0.24710472 0.21862654 0.17128956 0.13440038]\n",
      "[0.22354518 0.27384076 0.20999444 0.17527097 0.11734855]\n",
      "[0.2158409  0.26555115 0.21817598 0.17656213 0.12386981]\n",
      "[0.22100946 0.223006   0.22231913 0.19064821 0.14301725]\n",
      "\n",
      "[0.21935596 0.23372708 0.22242907 0.19026117 0.13422672]\n",
      "[0.2158592  0.25384578 0.21756692 0.18850681 0.12422136]\n",
      "[0.21127497 0.25586715 0.22241354 0.18654318 0.12390111]\n",
      "[0.21462943 0.2811868  0.21324658 0.17272075 0.11821648]\n",
      "[0.21446793 0.25435683 0.22383706 0.17793687 0.12940137]\n",
      "\n",
      "[0.21740802 0.23350064 0.22048783 0.19379099 0.13481241]\n",
      "[0.21698773 0.21502514 0.22099672 0.20662811 0.14036225]\n",
      "[0.21991357 0.23870303 0.22161433 0.18500236 0.13476668]\n",
      "[0.2248452  0.24521127 0.21925233 0.17841414 0.13227706]\n",
      "[0.22553477 0.1837293  0.2287521  0.19910344 0.16288035]\n",
      "\n",
      "[0.21145624 0.21007143 0.2236259  0.20776336 0.14708303]\n",
      "[0.2131517  0.26882592 0.21922174 0.1793756  0.11942507]\n",
      "[0.2189298  0.24709255 0.22234711 0.18060762 0.1310229 ]\n",
      "[0.21142189 0.24945758 0.22310078 0.19114785 0.12487195]\n",
      "[0.22721773 0.20876107 0.22293803 0.1893524  0.15173084]\n",
      "\n",
      "[0.22066924 0.24330792 0.2177999  0.18093833 0.13728462]\n",
      "[0.22160248 0.18160199 0.22776276 0.20228186 0.1667509 ]\n",
      "[0.20886233 0.23471731 0.22819668 0.1972215  0.13100214]\n",
      "[0.22450598 0.27442217 0.21211311 0.16538094 0.1235777 ]\n",
      "[0.21351853 0.23500505 0.22063439 0.19451156 0.13633038]\n",
      "\n",
      "[0.21146883 0.25213903 0.21988031 0.1932217  0.12329004]\n",
      "[0.21695477 0.23473683 0.21879505 0.19101058 0.1385028 ]\n",
      "[0.21795213 0.23501207 0.21694519 0.19321567 0.13687496]\n",
      "[0.21104777 0.22558662 0.2241704  0.20106569 0.13812959]\n",
      "[0.2181849  0.22392985 0.22505854 0.19271329 0.14011332]\n",
      "\n",
      "[0.20553717 0.24218756 0.22199723 0.20061585 0.12966223]\n",
      "[0.19415112 0.2763825  0.21920586 0.19098946 0.1192711 ]\n",
      "[0.21986268 0.22658177 0.22494718 0.18589027 0.14271818]\n",
      "[0.22777738 0.24734014 0.222863   0.17252272 0.12949671]\n",
      "[0.21947376 0.2042523  0.22399655 0.20045093 0.15182649]\n",
      "\n",
      "[0.20322298 0.2565502  0.21763058 0.20082937 0.12176695]\n",
      "[0.21698399 0.28130856 0.22111972 0.1686392  0.11194859]\n",
      "[0.22019549 0.22528169 0.22655222 0.19218563 0.13578492]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2242059  0.21298023 0.22037363 0.19078308 0.1516572 ]\n",
      "[0.20396619 0.25523153 0.22252809 0.1957742  0.12249994]\n",
      "\n",
      "[0.21333747 0.20636319 0.22664948 0.20545466 0.14819522]\n",
      "[0.20151992 0.28966737 0.21825255 0.17881928 0.11174096]\n",
      "[0.21180518 0.22751749 0.22716019 0.19526762 0.13824949]\n",
      "[0.21623227 0.2227236  0.22569863 0.19739991 0.1379456 ]\n",
      "[0.22215946 0.23508789 0.21731377 0.182012   0.14342684]\n",
      "\n",
      "[0.2152606  0.24317682 0.22295639 0.1923544  0.12625185]\n",
      "[0.21425165 0.24918205 0.21947832 0.18672948 0.13035853]\n",
      "[0.21657386 0.20686142 0.22799271 0.20631416 0.14225787]\n",
      "[0.2198012  0.18842211 0.22526214 0.20336626 0.16314822]\n",
      "[0.21362345 0.24957725 0.2227816  0.18606177 0.12795587]\n",
      "\n",
      "[0.20879415 0.28129983 0.21555294 0.18973482 0.10461818]\n",
      "[0.20693961 0.2928036  0.20534395 0.18752693 0.10738587]\n",
      "[0.22713229 0.21451686 0.22164981 0.18781193 0.14888912]\n",
      "[0.22520345 0.18221782 0.22888982 0.19892257 0.16476624]\n",
      "[0.21625517 0.23595075 0.22402875 0.18682045 0.13694482]\n"
     ]
    }
   ],
   "source": [
    "for x in proba_seq:\n",
    "    print()\n",
    "    for xx in x:\n",
    "        print(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  2 12 10  7]\n",
      " [ 3 13  7  8  2]\n",
      " [10 17  9 16  8]\n",
      " [19  9  7  1 14]\n",
      " [ 8 18  4 13 10]\n",
      " [12 13  3  4  6]\n",
      " [ 8  5  2 18 15]\n",
      " [ 3  2 12 17  1]\n",
      " [12  8 15 13 14]\n",
      " [18 10 12 17 11]\n",
      " [ 6 17 13  5 10]\n",
      " [ 5 10 13 17  3]\n",
      " [18 14 16 19  0]\n",
      " [15  1 14 19  6]\n",
      " [ 2  8  5  6  1]\n",
      " [ 6  5 16  7  9]\n",
      " [ 6  9  7 16  2]\n",
      " [ 3 10 13 11  4]\n",
      " [17  9  0 15  7]\n",
      " [16  8  9 11  5]\n",
      " [10 15 13  1  2]\n",
      " [ 6  3  8  4 19]\n",
      " [14 18 15  0 19]\n",
      " [19  2 16 18  1]\n",
      " [ 9 13 15  8  1]\n",
      " [14  9 15 11  2]\n",
      " [ 2  3  5 13 10]\n",
      " [13 11 14  5  0]\n",
      " [ 7  0 10 11  1]\n",
      " [15  8  3  5 13]\n",
      " [10 13  7  1 16]\n",
      " [ 4 15 13  5 12]]\n",
      "[[0 4 3 3 0]\n",
      " [4 4 4 4 0]\n",
      " [4 4 4 4 2]\n",
      " [4 4 0 1 0]\n",
      " [0 4 1 1 0]\n",
      " [1 0 0 0 3]\n",
      " [1 4 4 0 2]\n",
      " [0 3 3 1 2]\n",
      " [4 3 0 4 4]\n",
      " [0 2 0 3 0]\n",
      " [1 0 4 0 1]\n",
      " [0 0 3 0 3]\n",
      " [1 3 4 3 2]\n",
      " [0 0 4 4 0]\n",
      " [2 4 0 0 0]\n",
      " [0 1 0 0 1]\n",
      " [0 1 1 4 4]\n",
      " [0 2 1 1 0]\n",
      " [0 4 1 4 2]\n",
      " [0 1 2 3 4]\n",
      " [2 1 4 3 4]\n",
      " [3 2 2 3 1]\n",
      " [1 0 3 4 0]\n",
      " [2 0 4 0 4]\n",
      " [3 2 3 3 4]\n",
      " [4 3 4 4 0]\n",
      " [0 2 4 0 1]\n",
      " [4 3 4 0 3]\n",
      " [3 1 0 0 4]\n",
      " [0 2 0 4 0]\n",
      " [1 0 3 0 4]\n",
      " [4 2 0 2 3]]\n",
      "[0.6 0.4 0.4 0.6 0.6 0.6 0.8 0.8 0.6 0.6 0.6 0.4 0.8 0.4 0.6 0.4 0.6 0.6\n",
      " 0.8 1.  0.8 0.6 0.8 0.6 0.6 0.6 0.8 0.6 0.8 0.6 0.8 0.8]\n",
      "[[[0.29940635 0.15531819 0.12885839 0.16818833 0.24822867]\n",
      "  [0.29066718 0.15802214 0.12061422 0.16397749 0.26671895]\n",
      "  [0.30584615 0.14710905 0.1242556  0.15687343 0.26591572]\n",
      "  [0.29384047 0.15841277 0.13640746 0.17254631 0.23879299]\n",
      "  [0.29311162 0.15897028 0.12414666 0.16839603 0.25537544]]\n",
      "\n",
      " [[0.3115418  0.15206231 0.10264262 0.16647644 0.2672769 ]\n",
      "  [0.2878336  0.15553372 0.13764407 0.15485463 0.26413402]\n",
      "  [0.291286   0.15868403 0.13256843 0.16566075 0.25180084]\n",
      "  [0.2852245  0.16090241 0.1552881  0.1710754  0.22750957]\n",
      "  [0.2886458  0.15834898 0.12790413 0.1618141  0.26328698]]\n",
      "\n",
      " [[0.29533792 0.15615796 0.14269584 0.17015693 0.23565137]\n",
      "  [0.3083341  0.14735034 0.11249274 0.15973668 0.27208614]\n",
      "  [0.30847317 0.14808829 0.12027161 0.16211483 0.26105216]\n",
      "  [0.28670532 0.15569612 0.15828416 0.15913726 0.24017712]\n",
      "  [0.286899   0.16109456 0.15347227 0.17287254 0.22566174]]\n",
      "\n",
      " [[0.28985065 0.1616869  0.10880222 0.16865109 0.27100918]\n",
      "  [0.30739522 0.14869347 0.11115941 0.1617543  0.2709977 ]\n",
      "  [0.2942896  0.1573889  0.12193196 0.1656514  0.26073807]\n",
      "  [0.29492858 0.15446042 0.13126403 0.16101237 0.25833464]\n",
      "  [0.31844148 0.14493307 0.11344714 0.1635504  0.25962782]]\n",
      "\n",
      " [[0.2843967  0.16328765 0.1511821  0.17398739 0.22714612]\n",
      "  [0.297375   0.15056694 0.13649076 0.15533105 0.2602363 ]\n",
      "  [0.3011745  0.14920491 0.14205815 0.15827301 0.24928941]\n",
      "  [0.28830037 0.15707853 0.13143708 0.15778702 0.26539692]\n",
      "  [0.29327634 0.15761171 0.14100924 0.17067567 0.23742709]]\n",
      "\n",
      " [[0.30186155 0.14797887 0.13014628 0.15397449 0.2660387 ]\n",
      "  [0.2848     0.15838991 0.13460395 0.1564823  0.26572394]\n",
      "  [0.30678806 0.15284692 0.10328192 0.16443776 0.27264535]\n",
      "  [0.29872283 0.149079   0.14435403 0.15527947 0.25256464]\n",
      "  [0.2995661  0.14701167 0.16169906 0.15445565 0.23726761]]\n",
      "\n",
      " [[0.28882477 0.1601676  0.14910546 0.17232643 0.22957572]\n",
      "  [0.29887378 0.15296055 0.1298107  0.16508095 0.25327393]\n",
      "  [0.29177755 0.15708323 0.12261958 0.16268493 0.26583475]\n",
      "  [0.2998808  0.14850734 0.13598064 0.15380073 0.26183054]\n",
      "  [0.29341316 0.15234467 0.1446998  0.15541591 0.25412652]]\n",
      "\n",
      " [[0.30936217 0.15244707 0.1025347  0.1662348  0.26942125]\n",
      "  [0.2881688  0.15893471 0.1264935  0.16263558 0.26376748]\n",
      "  [0.30333278 0.14768158 0.13015302 0.15525247 0.26358014]\n",
      "  [0.30482087 0.14875485 0.114088   0.15901156 0.2733247 ]\n",
      "  [0.2920726  0.15447529 0.14339064 0.15987404 0.25018737]]\n",
      "\n",
      " [[0.30513087 0.14641647 0.12379607 0.15355866 0.2710979 ]\n",
      "  [0.28562763 0.16188712 0.14702632 0.1706193  0.23483966]\n",
      "  [0.29228815 0.15165913 0.14352342 0.15256327 0.25996605]\n",
      "  [0.28901508 0.15527576 0.12886801 0.15428375 0.27255738]\n",
      "  [0.3165298  0.14608146 0.11583104 0.16296507 0.25859255]]\n",
      "\n",
      " [[0.29948968 0.1492699  0.1364013  0.15462379 0.26021525]\n",
      "  [0.29511243 0.15697747 0.1381954  0.1708223  0.23889238]\n",
      "  [0.30705422 0.1458805  0.12576926 0.15543185 0.26586422]\n",
      "  [0.30759555 0.14793694 0.10817311 0.16014819 0.27614623]\n",
      "  [0.3008474  0.15365505 0.1302397  0.1661762  0.24908164]]\n",
      "\n",
      " [[0.3046952  0.1453439  0.152275   0.15502381 0.2426622 ]\n",
      "  [0.30641732 0.14808846 0.10528047 0.15886277 0.28135103]\n",
      "  [0.2894214  0.1560833  0.12717055 0.156004   0.2713208 ]\n",
      "  [0.2963365  0.15491797 0.12582032 0.16451056 0.25841472]\n",
      "  [0.29451323 0.15723757 0.13467747 0.16950674 0.24406503]]\n",
      "\n",
      " [[0.296208   0.15412256 0.12977819 0.1637776  0.25611368]\n",
      "  [0.2930991  0.157306   0.13904169 0.16865443 0.24189879]\n",
      "  [0.2883031  0.1558999  0.13196439 0.15493384 0.2688988 ]\n",
      "  [0.305536   0.14806114 0.10935745 0.15792944 0.279116  ]\n",
      "  [0.31004277 0.15116006 0.09977726 0.16433497 0.274685  ]]\n",
      "\n",
      " [[0.30097112 0.1478004  0.13638334 0.15332156 0.2615236 ]\n",
      "  [0.32267162 0.14493893 0.11482592 0.16589738 0.25166613]\n",
      "  [0.28812867 0.1551515  0.15255426 0.15858622 0.24557932]\n",
      "  [0.28962302 0.15941192 0.11445673 0.17048824 0.26602   ]\n",
      "  [0.30807838 0.14504893 0.14916395 0.15710744 0.24060135]]\n",
      "\n",
      " [[0.29436046 0.15043609 0.1410312  0.15262195 0.26155034]\n",
      "  [0.29554993 0.15336333 0.13184671 0.15952842 0.2597116 ]\n",
      "  [0.31878966 0.14478643 0.11356875 0.16300549 0.25984973]\n",
      "  [0.2890556  0.16038533 0.10956179 0.168636   0.2723613 ]\n",
      "  [0.3067116  0.145438   0.14869456 0.15584871 0.24330713]]\n",
      "\n",
      " [[0.2904584  0.15821595 0.12295508 0.16441444 0.2639561 ]\n",
      "  [0.2849121  0.16356224 0.14971732 0.1753927  0.22641563]\n",
      "  [0.29610232 0.15581432 0.129885   0.16790617 0.2502922 ]\n",
      "  [0.30728796 0.14628248 0.1539311  0.15939371 0.23310468]\n",
      "  [0.29383832 0.155247   0.13690668 0.1630691  0.25093898]]\n",
      "\n",
      " [[0.30825123 0.14447656 0.15222523 0.15596813 0.23907885]\n",
      "  [0.2979334  0.1539598  0.12733082 0.16463737 0.2561386 ]\n",
      "  [0.2876133  0.15572283 0.15128295 0.15852548 0.24685541]\n",
      "  [0.29551604 0.15623462 0.12517022 0.1649966  0.25808245]\n",
      "  [0.3087001  0.14785449 0.1147707  0.16119793 0.26747674]]\n",
      "\n",
      " [[0.30785346 0.14491823 0.15581843 0.15681225 0.23459767]\n",
      "  [0.3081973  0.14829767 0.11853765 0.16177233 0.26319507]\n",
      "  [0.29503092 0.15632384 0.12980498 0.16536255 0.25347775]\n",
      "  [0.2870303  0.15513249 0.15720372 0.15809871 0.24253476]\n",
      "  [0.29186636 0.156766   0.12390766 0.16213745 0.26532254]]\n",
      "\n",
      " [[0.31140083 0.15191628 0.10223547 0.16680272 0.2676447 ]\n",
      "  [0.29369402 0.15630297 0.14394565 0.16931693 0.23674032]\n",
      "  [0.2880168  0.15619397 0.1348317  0.15614711 0.26481047]\n",
      "  [0.29719907 0.15628783 0.1359603  0.16763453 0.24291822]\n",
      "  [0.30077305 0.14833911 0.14543942 0.15660042 0.24884802]]\n",
      "\n",
      " [[0.30907753 0.14561366 0.10508357 0.15635994 0.2838653 ]\n",
      "  [0.30937892 0.14688465 0.11272945 0.15922542 0.27178156]\n",
      "  [0.30888253 0.14413089 0.14481813 0.15467887 0.24748965]\n",
      "  [0.2957296  0.14929965 0.14166471 0.15130398 0.26200214]\n",
      "  [0.2965569  0.15479456 0.12332989 0.16234562 0.26297304]]\n",
      "\n",
      " [[0.28807357 0.15516774 0.15565795 0.15955393 0.2415468 ]\n",
      "  [0.28971317 0.15947592 0.15260284 0.17267464 0.22553347]\n",
      "  [0.31093463 0.14783257 0.11894062 0.16338742 0.25890476]\n",
      "  [0.302107   0.15293114 0.13413475 0.16652533 0.24430174]\n",
      "  [0.29969832 0.15260893 0.13312732 0.16560563 0.24895978]]\n",
      "\n",
      " [[0.2949639  0.15718889 0.13236952 0.16994148 0.24553622]\n",
      "  [0.29335234 0.15216546 0.13881788 0.15455066 0.2611136 ]\n",
      "  [0.2897168  0.1561086  0.12446116 0.15656288 0.2731505 ]\n",
      "  [0.29489064 0.15422861 0.1300037  0.16071223 0.2601649 ]\n",
      "  [0.29086843 0.1575815  0.11627144 0.16238588 0.2728927 ]]\n",
      "\n",
      " [[0.30056906 0.14652777 0.16563176 0.15601678 0.23125458]\n",
      "  [0.30993804 0.15259679 0.10542356 0.16683768 0.26520398]\n",
      "  [0.2836128  0.1617229  0.15870893 0.17214039 0.22381498]\n",
      "  [0.2991343  0.14881025 0.14949308 0.1565377  0.24602467]\n",
      "  [0.28346667 0.16032346 0.12338033 0.17162439 0.26120517]]\n",
      "\n",
      " [[0.32140496 0.14517382 0.11099331 0.16470766 0.25772023]\n",
      "  [0.30085343 0.14777361 0.13127515 0.15233997 0.26775792]\n",
      "  [0.29481825 0.15105483 0.13985847 0.15346652 0.26080185]\n",
      "  [0.308279   0.14511557 0.14417395 0.15620375 0.2462277 ]\n",
      "  [0.29032868 0.1597107  0.11039655 0.16817825 0.2713858 ]]\n",
      "\n",
      " [[0.2871435  0.15898392 0.11546353 0.17314267 0.26526636]\n",
      "  [0.29187104 0.15738426 0.12232386 0.16363537 0.2647855 ]\n",
      "  [0.28713194 0.15594023 0.15459754 0.15975164 0.24257873]\n",
      "  [0.30008957 0.14863081 0.13828357 0.15453051 0.25846565]\n",
      "  [0.29591823 0.15318085 0.13818146 0.16112071 0.2515987 ]]\n",
      "\n",
      " [[0.30764294 0.14835186 0.11292554 0.16072035 0.2703593 ]\n",
      "  [0.29036015 0.15497959 0.1264472  0.15497202 0.27324107]\n",
      "  [0.2937403  0.15140158 0.14087245 0.15327743 0.26070824]\n",
      "  [0.28707486 0.16158208 0.14483835 0.1713859  0.23511878]\n",
      "  [0.29553387 0.1530904  0.1322059  0.1590559  0.26011387]]\n",
      "\n",
      " [[0.3227712  0.14472605 0.11584377 0.16537063 0.25128832]\n",
      "  [0.30975786 0.14820302 0.11604984 0.16222174 0.26376763]\n",
      "  [0.29488266 0.15046242 0.14660856 0.15357158 0.25447476]\n",
      "  [0.30108184 0.15304424 0.13103133 0.1661028  0.24873982]\n",
      "  [0.29265946 0.15647589 0.12242692 0.1619946  0.2664432 ]]\n",
      "\n",
      " [[0.28868157 0.15869719 0.12282927 0.1626012  0.2671908 ]\n",
      "  [0.3115392  0.1522082  0.09827042 0.16722402 0.27075815]\n",
      "  [0.29586786 0.15483284 0.12962495 0.1657155  0.25395882]\n",
      "  [0.28746447 0.15701793 0.13122167 0.15663956 0.26765633]\n",
      "  [0.2924093  0.15827817 0.13886918 0.17067264 0.23977062]]\n",
      "\n",
      " [[0.29133084 0.15485837 0.12658036 0.15608028 0.27115008]\n",
      "  [0.30168    0.1533671  0.12734692 0.16565925 0.25194672]\n",
      "  [0.322386   0.14545272 0.11159353 0.16624944 0.25431827]\n",
      "  [0.2983084  0.15350395 0.12692563 0.16417657 0.25708538]\n",
      "  [0.3080583  0.1453016  0.14610164 0.1570822  0.24345623]]\n",
      "\n",
      " [[0.2959742  0.15687558 0.1212613  0.1671154  0.25877357]\n",
      "  [0.30870068 0.14557494 0.14353944 0.15898782 0.24319708]\n",
      "  [0.29666483 0.15675561 0.13370526 0.17165482 0.24121937]\n",
      "  [0.3021804  0.15359022 0.1250604  0.16759755 0.25157142]\n",
      "  [0.29624963 0.15471919 0.13033545 0.16348772 0.25520805]]\n",
      "\n",
      " [[0.2916397  0.1520353  0.14655174 0.15263358 0.25713962]\n",
      "  [0.28612596 0.16054821 0.1510552  0.1696324  0.23263827]\n",
      "  [0.31223464 0.15089397 0.09921525 0.16457953 0.2730766 ]\n",
      "  [0.29747015 0.1524315  0.13104606 0.16206056 0.25699174]\n",
      "  [0.28899443 0.15465474 0.13195877 0.15347813 0.27091396]]\n",
      "\n",
      " [[0.29565975 0.15682788 0.13349131 0.17013077 0.24389026]\n",
      "  [0.29038817 0.15601525 0.12570855 0.15701456 0.27087346]\n",
      "  [0.29500186 0.15680963 0.12217952 0.16548942 0.26051956]\n",
      "  [0.29551816 0.15410723 0.13128181 0.16114542 0.25794736]\n",
      "  [0.28703618 0.1570433  0.14702798 0.15993908 0.2489534 ]]\n",
      "\n",
      " [[0.30124444 0.14867572 0.13503471 0.15564233 0.2594028 ]\n",
      "  [0.29151598 0.15274087 0.13961513 0.15330113 0.2628269 ]\n",
      "  [0.2880452  0.156374   0.12520915 0.1550399  0.2753318 ]\n",
      "  [0.2953575  0.15514238 0.12449721 0.1639008  0.26110223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [0.30450714 0.14674391 0.12129466 0.1536208  0.27383348]]]\n"
     ]
    }
   ],
   "source": [
    "print(state_seq)\n",
    "print(action_seq)\n",
    "print(reward_seq)\n",
    "print(proba_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0]\n",
      " [0 2 2 2]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    inputs = tf.constant(np.array([[0,0], [0,1], [0,2], [1,1], [1,2], [1,3]]))\n",
    "    \n",
    "    updates = tf.constant(np.array([1,1,1] +[2,2,2]))\n",
    "    \n",
    "    scatter = tf.scatter_nd(inputs, updates, shape = [2,4])\n",
    "    \n",
    "    print(sess.run(scatter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 2 2 2 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.reshape(tf.tile(tf.expand_dims([1, 2, 3], -1),  [1, 3]), [-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [1, 2, 3],\n",
       "       [0, 0, 0],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([[[0,1,2], [1,2,3]], [[0,0,0], [1,1,1]]], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 0.]\n",
      " [0. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((2,4))\n",
    "x[(np.repeat(np.arange(2), 3), np.array([[0,1,2], [1,2,3]]).ravel())] = 1\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1, 1],\n",
       "       [0, 1, 2, 1, 2, 3]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array((np.repeat(np.arange(2), 3), np.array([[0,1,2], [1,2,3]]).ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 1, 1, 1, 1], dtype=int64),\n",
       " array([0, 1, 2, 3, 0, 1, 2, 3], dtype=int64))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.ones((2,4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
